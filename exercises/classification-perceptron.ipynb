{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bf8026c",
   "metadata": {},
   "source": [
    "# Classification task using a perceptron\n",
    "\n",
    "Create a dataset with three classes, each class has N objects, represented by two variables X1 and X2 according to the following requirements:\n",
    "\n",
    "+ N is equal to 100\n",
    "+ X1 is distributed:\n",
    "    1. for class 1, a normal distribution with mean -1 and standard deviation 0.5\n",
    "    2. for class 2, a normal distribution with mean 2.5 and standard deviation 1\n",
    "    3. for class 3, a normal distribution with mean 4 and standard deviation 1\n",
    "+ X2 is distributed:\n",
    "    1. for class 1, an exponential distribution with scale parameter 3\n",
    "    2. for class 2, a lognormal distribution with mean 0.5 and standard deviation 0.5\n",
    "    3. for class 3, a Poisson distribution with lambda 2.0 plus a constant equal to 5\n",
    "\n",
    "Each object has a label y attached (1, 2, or 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51a614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# generate N points per class\n",
    "N = 100\n",
    "\n",
    "\n",
    "# generate points\n",
    "X1_1 = np.random.normal(loc = -1, scale =  0.5, size = N)\n",
    "X1_2 = np.random.normal(loc = 2.5, scale = 1, size = N)\n",
    "X1_3 = np.random.normal(loc = 4, loc = 1, size = N)\n",
    "\n",
    "X2_1 = np.random.exponential(scale = 3, size = N)\n",
    "X2_2 = np.random.lognormal(mean = 0.5, sigma = 0.5, size = N)\n",
    "X2_3 = np.random.poission(lam = 2, size = N) + 5\n",
    "\n",
    "\n",
    "# For each set of points, we need the labels\n",
    "y1 = np.ones(N) # 100 labels equal to one\n",
    "\n",
    "# 200 more lables, for X2_2 = np.random.lognormal(mean = 0.5, sigma = 0.5, size = N)\n",
    "X2_3 = np.random.poission(lam = 2, size = N) + 5\n",
    "\n",
    "\n",
    "# For each set of points, we need the labels\n",
    "y1 = np.ones(N) # 100 labels equal to one\n",
    "\n",
    "# 200 more lables, for the other two class\n",
    "\n",
    "# controlla file txt please \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30602c9d",
   "metadata": {},
   "source": [
    "## Plot the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193dbef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91709f4a",
   "metadata": {},
   "source": [
    "## Create data matrix\n",
    "\n",
    "Create a matrix of points X (each row is an object) and a vector y of labels. Remember that we need the coordinate X0 for the bias term (all ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack vectors\n",
    "X = np.stack((np.ones(N * 3),\n",
    "              np.concatenate((X1_1, X1_2, X1_3)), \n",
    "              np.concatenate((X2_1, X2_2, X2_3))), \n",
    "             axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c820f645",
   "metadata": {},
   "source": [
    "## Choose category \n",
    "\n",
    "We want to train a binary classifier for class 3. To this purpose, create a vector of labels y_class that contains 1 for each object belonging to the class under study (positive class) and -1 to all the other objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c16b138",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_class = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb526c",
   "metadata": {},
   "source": [
    "### Plot this binary problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 1], X[:, 2], c = y_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36eeb13",
   "metadata": {},
   "source": [
    "## Define the Sum of squares error function\n",
    "\n",
    "Write the function sse(X, y, w) that takes the data matrix X, the labels y, and the vector of paraterers w and computes the error in terms of sum of squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse(X, y, w):\n",
    "    error = np.sum(np.square(y - np.dot(X, w)))\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18c0253",
   "metadata": {},
   "source": [
    "## Train the perceptron with a mini-batch stochastic gradient descent\n",
    "\n",
    "Set the values of the vector of parameters w with values drawn from a uniform distribution within the range \\[-1. 1\\].\n",
    "Use a learning parameter eta equal to 1e-5 and a batch size of 10 objects. Set the maximum number of epochs to 100.\n",
    "Save in the vector sse_epoch, the values of the sum of squares error for each epoch. Save in the vector errors_epoch, the number of objects misclassified at each epoch.\n",
    "Remember to shuffle the dataset at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f8ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate w_0,....,w_n\n",
    "w = np.random.uniform(low = -1, high = 1, size = 3)\n",
    "\n",
    "# plot inizial weight vector\n",
    "#plt.plot([np.min(X[:, 1]), np.max(X[:, 1])], [np.min(X[:, 1]) * (-w[1]/w[2]) - w[0]/w[2], np.max(X[:, 1]) * (-w[1]/w[2]) - w[0]/w[2]])\n",
    "\n",
    "#X = np.hstack((X0, np.vstack((X1, X2))))\n",
    "plt.scatter(X[:, 1], X[:, 2], c=y_class)\n",
    "\n",
    "# set learning rate 0 < eta <= 1\n",
    "eta = \n",
    "\n",
    "# set mini batch size\n",
    "batch_size = \n",
    "\n",
    "# set max epochs\n",
    "max_epochs = \n",
    "\n",
    "# track total error per epoch\n",
    "sse_epoch = np.zeros(max_epochs + 1)\n",
    "\n",
    "# set checkpoint\n",
    "errors_epoch = np.zeros(max_epochs + 1)\n",
    "\n",
    "for epochs in range(max_epochs):\n",
    "    \n",
    "    # compute error\n",
    "    sse_epoch[epochs] = \n",
    "    errors_epoch[epochs] = \n",
    "    \n",
    "    # generate random permutation\n",
    "    rand_perm = np.random.permutation(range(y_class.shape[0]))\n",
    "    X = X[rand_perm, :]\n",
    "    y_class = y_class[rand_perm]\n",
    "    \n",
    "    # mini-batch learning\n",
    "    for j in range(0, y_class.shape[0], batch_size):\n",
    "        \n",
    "        X_batch = \n",
    "        \n",
    "        y_batch = \n",
    "        \n",
    "        errors = \n",
    "\n",
    "        w = w + eta * np.dot(np.transpose(X_batch), errors)    \n",
    "\n",
    "sse_epoch[epochs + 1] = sse(X, y_class, w)\n",
    "errors_epoch[epochs + 1] = sum((y_class * np.sign(np.dot(X, w))) < 0)\n",
    "\n",
    "#print(eta)\n",
    "print(\"# of errors = \", errors_epoch[-1])\n",
    "plt.plot([np.min(X[:, 1]), np.max(X[:, 1])], \n",
    "         [np.min(X[:, 1]) * (-w[1]/w[2]) - w[0]/w[2], np.max(X[:, 1]) * (-w[1]/w[2]) - w[0]/w[2]],\n",
    "        c = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86445ce4",
   "metadata": {},
   "source": [
    "## Plot number of errors per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(max_epochs+1), errors_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a18977",
   "metadata": {},
   "source": [
    "# Polynomial regression task\n",
    "\n",
    "In this exercies, we will reuse the coordinate X1 to create a regression problem. The output Y (the \"oracle\" target function) is a cubic function aX^3 + bX^2 + cX + d with values a = -1, b = 2, c = -3, d = 4. Moreover, we sum some random noise with a gaussian distribution (mean zero, standard deviation 2.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a55d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate (oracle) quadratic target function\n",
    "\n",
    "# plot data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adb301c",
   "metadata": {},
   "source": [
    "## Create data matrix\n",
    "Suppose that your hypohtesis is a quadratic function, generate the data matrix accordingly (remember the X0) and save it into the variable X_reg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccfff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create (quadratic) data matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f352f40f",
   "metadata": {},
   "source": [
    "## Find the optimal vector of parameters\n",
    "In this case, we will try to find the optimal w using the closed form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb9b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find closed form solution\n",
    "# w = (X^T  X)^-1 (X^T y)\n",
    "\n",
    "# plot points\n",
    "plt.plot(X[:, 1], y, '.')\n",
    "\n",
    "# generate grid of points\n",
    "x_grid = np.linspace(np.min(X[:, 1]), np.max(X[:, 1]), 100)\n",
    "\n",
    "# plot line\n",
    "plt.plot(x_grid, w[0] + x_grid * w[1] + x_grid**2 * w[2] + x_grid**3 * w[3] + x_grid**4 * w[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6062ad8f",
   "metadata": {},
   "source": [
    "## Check the curvature of the solution\n",
    "\n",
    "Why does this solution look like a line? Try to plot the parabola and think about the reasons of this shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d7217",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_g = np.linspace(-50, 50, 100)\n",
    "plt.plot(x_g, w[0] + x_g * w[1] + x_g**2 * w[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7ecf01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
